{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Question2"
      ],
      "metadata": {
        "id": "cwmw4im_LbYS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDisF5n0LLDb"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorboard\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "#load data\n",
        "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\n",
        "\n",
        "\n",
        "trainX = trainX / 255.0\n",
        "testX = testX / 255.0\n",
        "\n",
        "\n",
        "for i in range(9):\n",
        "\tplt.subplot(330 + 1 + i)\n",
        "\tplt.imshow(trainX[i])\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nFor instance, inout[0] belongs to the\",trainY[0],\"th category! As shown below:\")\n",
        "tf.keras.utils.to_categorical(trainY)[0]  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential Model\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters=6, kernel_size=(5,5), strides=(1,1), activation='sigmoid', input_shape=(32, 32,3)),\n",
        "    keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=(5,5), strides=(1,1), activation='sigmoid'),\n",
        "    keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
        "    keras.layers.Conv2D(filters=120, kernel_size=(5,5), strides=(1,1), activation='sigmoid'),\n",
        "    keras.layers.Dense(84,activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# ADAM OPTIMIZER\n",
        "adam=keras.optimizers.Adam(learning_rate=0.001,name='Adam')\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "DbXk55ubLeBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    trainX,\n",
        "    trainY, \n",
        "    batch_size=64,\n",
        "    epochs=25, \n",
        "    callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "id": "zyWdXwmsLgvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "EL5Xqo_QLjzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "score = model.evaluate(testX, testY)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "E6rv8hHSLmlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Effect of learning rate on the training process?\n",
        "\n",
        "As LR increases, it takes more time for the convergence to occur. In this scenario, pre-defined epochs, 25 here, would not be enough for it. In other words, it may need more iterations to converge. However, accuracy increases even a bit, but may have an opposite impact on the test set accuracy.\n",
        "\n",
        "2. Effect of batch size on the training process?\n",
        "\n",
        "Batch size controls the accuracy of the estimate of the error gradient, and therefore, choosing large BS will harm the model.\n",
        "\n",
        "3. Trying different hyperparameters."
      ],
      "metadata": {
        "id": "ODl6VKTALolG"
      }
    }
  ]
}